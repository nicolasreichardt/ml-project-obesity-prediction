{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478c7b17",
   "metadata": {},
   "source": [
    "## Regularized Regression: Ridge & Lasso Models for Obesity Prediction\n",
    "\n",
    "This notebook builds Ridge and Lasso regression models to predict obesity levels based on lifestyle and physical features. \n",
    "After preparing the dataset with one-hot encoding for categorical variables and numeric mapping of obesity categories, \n",
    "the models are trained on 80% of the dataset and evaluated on the remaining 20% using Mean Squared Error (MSE) and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33afb165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE: 0.1754\n",
      "Ridge Regression - R² Score: 0.9559\n",
      "\n",
      "Lasso Regression - MSE: 0.5137\n",
      "Lasso Regression - R² Score: 0.8708\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the full cleaned dataset\n",
    "data = pd.read_feather('../processed_data/obesity_cleaned.feather')\n",
    "\n",
    "# Define target and features\n",
    "target_col = \"obesity_level\"\n",
    "y = data[target_col]\n",
    "X = data.drop(columns=[target_col])\n",
    "\n",
    "# List categorical columns\n",
    "categorical_cols = [\n",
    "    \"gender\", \"family_history_overweight\", \"high_caloric_food_freq\", \n",
    "    \"vegetables_freq\", \"main_meal_count\", \"snacking_freq\", \"smokes\",\n",
    "    \"water_intake\", \"calorie_tracking\", \"physical_activity_freq\",\n",
    "    \"screen_time_hours\", \"alcohol_consumption_freq\", \"transport_mode\"\n",
    "]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Map target classes to numbers\n",
    "obesity_mapping = {\n",
    "    'Insufficient_Weight': 0,\n",
    "    'Normal_Weight': 1,\n",
    "    'Overweight_Level_I': 2,\n",
    "    'Overweight_Level_II': 3,\n",
    "    'Obesity_Type_I': 4,\n",
    "    'Obesity_Type_II': 5,\n",
    "    'Obesity_Type_III': 6\n",
    "}\n",
    "y_encoded = y.map(obesity_mapping)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Ridge model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate Ridge\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "print(f\"Ridge Regression - MSE: {ridge_mse:.4f}\")\n",
    "print(f\"Ridge Regression - R² Score: {ridge_r2:.4f}\")\n",
    "\n",
    "# Train Lasso model\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate Lasso\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "\n",
    "print(f\"\\nLasso Regression - MSE: {lasso_mse:.4f}\")\n",
    "print(f\"Lasso Regression - R² Score: {lasso_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec37bf8",
   "metadata": {},
   "source": [
    "Comments on findings:\n",
    "\n",
    "- Ridge regression achieved very similar performance to the OLS model. This suggests that slight regularization didn't hurt the model's ability to predict obesity levels.\n",
    "- Lasso regression showed a noticeable drop in R² score & a higher MSE, indicating that Lasso's stronger feature selection effect may not be ideal for this dataset.\n",
    "- Overall, Ridge regression appears to be a better regularized alternative to OLS for this problem, while Lasso may be too restrictive for accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136e648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge alpha: 0.01\n",
      "Best Ridge R2: 0.9536\n",
      "Best Lasso alpha: 0.01\n",
      "Best Lasso R2: 0.9478\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using GridSearchCV (finding best alpha)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Define alpha values to test\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Ridge Regression \n",
    "ridge = Ridge()\n",
    "ridge_params = {'alpha': alphas}\n",
    "\n",
    "ridge_grid = GridSearchCV(ridge, ridge_params, scoring='r2', cv=5)  # 5-fold cross-validation\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Ridge alpha: {ridge_grid.best_params_['alpha']}\")\n",
    "print(f\"Best Ridge R2: {ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso(max_iter=10000)  # increase max_iter for convergence\n",
    "lasso_params = {'alpha': alphas}\n",
    "\n",
    "lasso_grid = GridSearchCV(lasso, lasso_params, scoring='r2', cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Lasso alpha: {lasso_grid.best_params_['alpha']}\")\n",
    "print(f\"Best Lasso R2: {lasso_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f928294",
   "metadata": {},
   "source": [
    "Findings after Hyperparameter Tuning:\n",
    "\n",
    "- The optimal alpha value for both Ridge & Lasso regression models was found to be 0.01\n",
    "- Ridge regression achieved an R² score of 0.9536 (very close to the OLS model) This confirms its stability and robustness\n",
    "- Lasso regression also significantly improved after tuning (R² = 0.9478, compared to its previous lower performance)\n",
    "- Overall, Ridge regression remains slightly better than Lasso for this dataset, but both models perform strongly after tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa_2025_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
