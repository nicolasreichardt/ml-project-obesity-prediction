{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Tree-Based Classification with GridSearchCV\n",
    "# =============================\n",
    "\n",
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Step 2: Load the Full Training and Test Sets\n",
    "# Replace with actual file paths\n",
    "train_df = pd.read_csv('train.csv')   # <-- Full training data WITH labels\n",
    "test_df = pd.read_csv('test.csv')     # <-- Test set WITHOUT labels\n",
    "\n",
    "# Step 3: Separate Features and Target\n",
    "# Replace 'target' with the actual name of your label column\n",
    "TARGET_COL = 'target'  # <-- Placeholder\n",
    "\n",
    "X = train_df.drop(columns=[TARGET_COL])\n",
    "y = train_df[TARGET_COL]\n",
    "X_test = test_df  # Assuming test_df is already preprocessed and has same features as X\n",
    "\n",
    "# Step 4: Split Training Data into Train/Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Define Helper Function for Evaluation\n",
    "def evaluate_model(model, name):\n",
    "    \"\"\"Evaluate the model on the validation set and print metrics.\"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_val, y_pred, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y_val, y_pred, average='weighted'))\n",
    "    print(\"F1 Score:\", f1_score(y_val, y_pred, average='weighted'))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "    return model.predict(X_test)\n",
    "\n",
    "# Step 6: Define Models and Hyperparameter Grids\n",
    "models_params = {\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [3, 5, 10, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [5, 10, None],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        \"model\": lgb.LGBMClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"num_leaves\": [31, 64],\n",
    "            \"learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting (sklearn)\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"learning_rate\": [0.05, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 7: Train, Tune, and Evaluate Each Model\n",
    "best_models = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, mp in models_params.items():\n",
    "    print(f\"\\n>>> Running GridSearchCV for {name}...\")\n",
    "    clf = GridSearchCV(\n",
    "        estimator=mp[\"model\"],\n",
    "        param_grid=mp[\"params\"],\n",
    "        cv=3,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Best Params for {name}: {clf.best_params_}\")\n",
    "    test_predictions[name] = evaluate_model(clf.best_estimator_, name)\n",
    "    best_models[name] = clf.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
