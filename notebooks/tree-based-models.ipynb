{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Risk Prediction using Tree-based models\n",
    "\n",
    "This notebook trains tree-based models to predict obesity levels based on multi-class classification. Baseline decision trees, random forests and XGBoost models will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                            confusion_matrix, f1_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split data from feather files\n",
    "train_path = os.path.join(\"..\", \"processed_data\", \"train_data.feather\")\n",
    "test_path = os.path.join(\"..\", \"processed_data\", \"test_data.feather\")\n",
    "\n",
    "train_df = pd.read_feather(train_path)\n",
    "test_df = pd.read_feather(test_path)\n",
    "\n",
    "# Split features and labels again\n",
    "y_train = train_df[\"obesity_level\"]\n",
    "X_train = train_df.drop(columns=[\"obesity_level\"])\n",
    "\n",
    "y_test = test_df[\"obesity_level\"]\n",
    "X_test = test_df.drop(columns=[\"obesity_level\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=[\"category\"]).columns\n",
    "numerical_cols = X_train.select_dtypes(include=[\"float64\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### While DecisionTreeClassifier and RandomForestClassifier can work with both numeric and string labels, XGBoostClassifier expects numeric class labels. Therefore we encode the targets into integers. After making the predictions, we'll convert the predicted integers back to labels for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "Best cross-validation accuracy: 0.9479\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "pipeline_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline_dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_dt = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add plots and markdown explanation cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 20, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.9230\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.9267\n",
      "\n",
      "Top 5 Important Features:\n",
      "         Feature  Importance\n",
      "2      weight_kg    0.283676\n",
      "0            age    0.101957\n",
      "1       height_m    0.093542\n",
      "4    gender_Male    0.043114\n",
      "3  gender_Female    0.036349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline_rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Helper function to get feature names after preprocessing\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from a ColumnTransformer\"\"\"\n",
    "    col_names = []\n",
    "    for transformer_in_columns in column_transformer.transformers_:\n",
    "        transformer_name, transformer, orig_columns = transformer_in_columns\n",
    "        if transformer == 'drop':\n",
    "            continue\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            names = transformer.get_feature_names_out(orig_columns)\n",
    "        else:  # for StandardScaler\n",
    "            names = orig_columns\n",
    "        col_names.extend(names)\n",
    "    return col_names\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = best_rf.named_steps['classifier'].feature_importances_\n",
    "features = get_feature_names(best_rf.named_steps['preprocessor'])\n",
    "\n",
    "# Create DataFrame for feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Important Features:\")\n",
    "print(importance_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: Use scikit-learn version 1.5.2: add to requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__colsample_bytree': 0.8, 'classifier__gamma': 0, 'classifier__learning_rate': 0.2, 'classifier__max_depth': 3, 'classifier__n_estimators': 200, 'classifier__subsample': 1.0}\n",
      "Best cross-validation accuracy: 0.9710\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.9598\n",
      "\n",
      "Top 5 Important Features:\n",
      "                       Feature  Importance\n",
      "3                gender_Female    0.145731\n",
      "4                  gender_Male    0.120098\n",
      "18            snacking_freq_no    0.115379\n",
      "2                    weight_kg    0.062848\n",
      "8   high_caloric_food_freq_yes    0.058439\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, n_jobs=1, \n",
    "                                objective='multi:softmax',\n",
    "                                eval_metric='mlogloss'))\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "y_pred = label_encoder.inverse_transform(y_pred)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = best_xgb.named_steps['classifier'].feature_importances_\n",
    "features = get_feature_names(best_xgb.named_steps['preprocessor'])\n",
    "\n",
    "# Create DataFrame for feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Important Features:\")\n",
    "print(importance_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to be evaluated\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\"),\n",
    "}\n",
    "\n",
    "# Define the hyperparameters for each model\n",
    "param_grids = {\n",
    "    \"Decision Tree\": {\n",
    "        \"model__max_depth\": [None, 5, 10, 15],\n",
    "        \"model__min_samples_split\": [2, 5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [None, 5, 10],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1, 2],\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__learning_rate\": [0.01, 0.1],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best score for Decision Tree: 0.9318754060365564\n",
      "Best parameters for Decision Tree: {'model__max_depth': 10, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best score for Random Forest: 0.9253524836268502\n",
      "Best parameters for Random Forest: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best score for XGBoost: 0.9632732252910294\n",
      "Best parameters for XGBoost: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the best models and their scores\n",
    "best_models = {}\n",
    "# Loop through each model and perform hyperparameter tuning\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    # Create a pipeline with preprocessing and the model\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Store the best model and its score\n",
    "    best_models[model_name] = {\n",
    "        \"model\": grid_search.best_estimator_,\n",
    "        \"score\": grid_search.best_score_,\n",
    "    }\n",
    "    print(f\"Best score for {model_name}: {grid_search.best_score_}\")\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree on the test set...\n",
      "Accuracy for Decision Tree: 0.9385342789598109\n",
      "F1 Score for Decision Tree: 0.9384826114039201\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.92      0.96      0.94        56\n",
      "      Normal_Weight       0.90      0.87      0.89        62\n",
      "     Obesity_Type_I       0.95      0.94      0.94        78\n",
      "    Obesity_Type_II       0.96      0.95      0.96        58\n",
      "   Obesity_Type_III       1.00      1.00      1.00        63\n",
      " Overweight_Level_I       0.90      0.93      0.91        56\n",
      "Overweight_Level_II       0.94      0.92      0.93        50\n",
      "\n",
      "           accuracy                           0.94       423\n",
      "          macro avg       0.94      0.94      0.94       423\n",
      "       weighted avg       0.94      0.94      0.94       423\n",
      "\n",
      "[[54  2  0  0  0  0  0]\n",
      " [ 5 54  0  0  0  3  0]\n",
      " [ 0  0 73  2  0  0  3]\n",
      " [ 0  0  3 55  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  4  0  0  0 52  0]\n",
      " [ 0  0  1  0  0  3 46]]\n",
      "Evaluating Random Forest on the test set...\n",
      "Accuracy for Random Forest: 0.9125295508274232\n",
      "F1 Score for Random Forest: 0.9120823379806683\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.92      0.96      0.94        56\n",
      "      Normal_Weight       0.81      0.76      0.78        62\n",
      "     Obesity_Type_I       0.96      0.95      0.95        78\n",
      "    Obesity_Type_II       0.98      0.98      0.98        58\n",
      "   Obesity_Type_III       1.00      1.00      1.00        63\n",
      " Overweight_Level_I       0.81      0.84      0.82        56\n",
      "Overweight_Level_II       0.88      0.88      0.88        50\n",
      "\n",
      "           accuracy                           0.91       423\n",
      "          macro avg       0.91      0.91      0.91       423\n",
      "       weighted avg       0.91      0.91      0.91       423\n",
      "\n",
      "[[54  2  0  0  0  0  0]\n",
      " [ 5 47  0  0  0  6  4]\n",
      " [ 0  1 74  1  0  1  1]\n",
      " [ 0  0  1 57  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  8  0  0  0 47  1]\n",
      " [ 0  0  2  0  0  4 44]]\n",
      "Evaluating XGBoost on the test set...\n",
      "Accuracy for XGBoost: 0.9621749408983451\n",
      "F1 Score for XGBoost: 0.9620510501496791\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.93      1.00      0.97        56\n",
      "      Normal_Weight       0.98      0.85      0.91        62\n",
      "     Obesity_Type_I       0.99      0.95      0.97        78\n",
      "    Obesity_Type_II       0.97      0.98      0.97        58\n",
      "   Obesity_Type_III       1.00      1.00      1.00        63\n",
      " Overweight_Level_I       0.87      0.98      0.92        56\n",
      "Overweight_Level_II       1.00      0.98      0.99        50\n",
      "\n",
      "           accuracy                           0.96       423\n",
      "          macro avg       0.96      0.96      0.96       423\n",
      "       weighted avg       0.96      0.96      0.96       423\n",
      "\n",
      "[[56  0  0  0  0  0  0]\n",
      " [ 4 53  0  0  0  5  0]\n",
      " [ 0  0 74  2  0  2  0]\n",
      " [ 0  0  1 57  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  1  0  0  0 55  0]\n",
      " [ 0  0  0  0  0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "  # Evaluate the best models on the test set\n",
    "for model_name, model_info in best_models.items():\n",
    "    print(f\"Evaluating {model_name} on the test set...\")\n",
    "    # Make predictions\n",
    "    y_pred = model_info[\"model\"].predict(X_test)\n",
    "    # Convert the predicted integers back to labels\n",
    "    y_pred = label_encoder.inverse_transform(y_pred)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Accuracy for {model_name}: {accuracy}\")\n",
    "    print(f\"F1 Score for {model_name}: {f1}\")\n",
    "    \n",
    "    # Print classification report and confusion matrix\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
